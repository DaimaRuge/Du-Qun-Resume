# Silero Models é¡¹ç›®æ·±åº¦åˆ†ææŠ¥å‘Š

> **é¡¹ç›®åœ°å€**: https://github.com/snakers4/silero-models  
> **åˆ†ææ—¥æœŸ**: 2026-02-22  
> **åˆ†æç›®çš„**: ä¸ºåŸºäº OpenClaw çš„ä¸‹ä¸€ä»£æ™ºèƒ½å®¶å±…æ¡†æ¶é›†æˆ TTS èƒ½åŠ›

---

## ğŸ“‹ ç›®å½•

- [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
- [æ ¸å¿ƒåŠŸèƒ½ä¸ç‰¹æ€§](#æ ¸å¿ƒåŠŸèƒ½ä¸ç‰¹æ€§)
- [ä»£ç æ¶æ„](#ä»£ç æ¶æ„)
- [é¡¹ç›®æ¨¡å—](#é¡¹ç›®æ¨¡å—)
- [æ–‡ä»¶ç›®å½•ç»“æ„](#æ–‡ä»¶ç›®å½•ç»“æ„)
- [æ ¸å¿ƒæŠ€æœ¯æ ˆ](#æ ¸å¿ƒæŠ€æœ¯æ ˆ)
- [æ ¸å¿ƒæ–‡ä»¶åˆ†æ](#æ ¸å¿ƒæ–‡ä»¶åˆ†æ)
- [OpenClaw æ™ºèƒ½å®¶å±…é›†æˆæ–¹æ¡ˆ](#openclaw-æ™ºèƒ½å®¶å±…é›†æˆæ–¹æ¡ˆ)
- [éƒ¨ç½²ä¸ä½¿ç”¨](#éƒ¨ç½²ä¸ä½¿ç”¨)
- [æœ€ä½³å®è·µä¸å»ºè®®](#æœ€ä½³å®è·µä¸å»ºè®®)

---

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

### åŸºæœ¬ä¿¡æ¯

- **é¡¹ç›®åç§°**: Silero Models
- **å®šä½**: é¢„è®­ç»ƒçš„æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰å’Œè¯­éŸ³è¯†åˆ«ï¼ˆSTTï¼‰æ¨¡å‹é›†åˆ
- **å¼€æºåè®®**: CC-NC-BY 4.0ï¼ˆéƒ¨åˆ† CIS åŸºç¡€æ¨¡å‹ä¸º MITï¼‰
- **ç»´æŠ¤å›¢é˜Ÿ**: Silero Team
- **æ´»è·ƒåº¦**: é«˜åº¦æ´»è·ƒï¼ŒæŒç»­æ›´æ–°ï¼ˆæœ€æ–° V5 ç‰ˆæœ¬ï¼‰

### æ ¸å¿ƒä¼˜åŠ¿

1. **ç«¯åˆ°ç«¯**: å®Œå…¨ç«¯åˆ°ç«¯çš„ç¥ç»ç½‘ç»œæ¨¡å‹
2. **å¤šè¯­è¨€æ”¯æŒ**: æ”¯æŒ 20+ è¯­è¨€ï¼ˆä¿„è¯­ã€è‹±è¯­ã€å¾·è¯­ã€è¥¿ç­ç‰™è¯­ã€æ³•è¯­ã€ä¸­æ–‡ç­‰ï¼‰
3. **é«˜è´¨é‡è¯­éŸ³**: è‡ªç„¶æµç•…çš„è¯­éŸ³åˆæˆæ•ˆæœ
4. **æç®€ä½¿ç”¨**: ä¸€è¡Œä»£ç å³å¯è°ƒç”¨ï¼Œæœ€å°åŒ–ä¾èµ–
5. **CPU/GPU å‹å¥½**: åœ¨ CPU ä¸Šä¹Ÿèƒ½å®ç°é«˜é€Ÿæ¨ç†
6. **è‡ªåŠ¨é‡éŸ³å¤„ç†**: ä¿„è¯­æ”¯æŒè‡ªåŠ¨é‡éŸ³å’ŒåŒå½¢å¼‚ä¹‰è¯å¤„ç†

---

## âœ¨ æ ¸å¿ƒåŠŸèƒ½ä¸ç‰¹æ€§

### 1. æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰

#### V5 ç‰ˆæœ¬ç‰¹æ€§
- **SSML æ”¯æŒ**: æ”¯æŒè¯­éŸ³åˆæˆæ ‡è®°è¯­è¨€ï¼Œå¯ç²¾ç¡®æ§åˆ¶è¯­éŸ³èŠ‚å¥ã€åœé¡¿ã€éŸ³è°ƒ
- **å¤šé‡‡æ ·ç‡**: 8000Hz / 24000Hz / 48000Hz
- **å¤šè¯´è¯äºº**: æ¯ä¸ªè¯­è¨€åŒ…å«å¤šä¸ªé«˜è´¨é‡å£°éŸ³é€‰é¡¹
- **è‡ªåŠ¨é‡éŸ³**: ä¿„è¯­æ¨¡å‹æ”¯æŒè‡ªåŠ¨é‡éŸ³å’ŒåŒå½¢å¼‚ä¹‰è¯å¤„ç†

#### æ”¯æŒçš„è¯­è¨€ï¼ˆV5 CIS æ¨¡å‹ï¼‰
| è¯­è¨€ | ä»£ç  | è¯´è¯äººæ•° | ç‰¹æ®Šæ”¯æŒ |
|------|------|---------|---------|
| ä¿„è¯­ | `ru` | 5+ | è‡ªåŠ¨é‡éŸ³ + åŒå½¢å¼‚ä¹‰è¯ |
| ä¹Œå…‹å…°è¯­ | `ukr` | 2 | - |
| å“ˆè¨å…‹è¯­ | `kaz` | 7 | - |
| é‘é¼è¯­ | `tat` | 20+ | - |
| ä¹Œå…¹åˆ«å…‹è¯­ | `uzb` | 3 | - |
| ç™½ä¿„ç½—æ–¯è¯­ | `bel` | 3 | - |
| æ ¼é²å‰äºšè¯­ | `kat` | 1 | å†…éƒ¨è½¬å†™ |
| äºšç¾å°¼äºšè¯­ | `hye` | 1 | å†…éƒ¨è½¬å†™ |
| é˜¿å¡æ‹œç–†è¯­ | `aze` | 1 | åŒå­—æ¯æ”¯æŒ |

### 2. è¯­éŸ³è¯†åˆ«ï¼ˆSTTï¼‰

- **å¤šè¯­è¨€**: è‹±è¯­ã€å¾·è¯­ã€è¥¿ç­ç‰™è¯­ã€ä¹Œå…‹å…°è¯­
- **å¤šæ ¼å¼**: JIT / ONNX / TensorFlow
- **é‡åŒ–ç‰ˆæœ¬**: æä¾›é‡åŒ–æ¨¡å‹ä»¥é™ä½èµ„æºæ¶ˆè€—
- **å®æ—¶æ€§**: é€‚åˆå®æ—¶è¯­éŸ³è¯†åˆ«åœºæ™¯

### 3. è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆVADï¼‰

- **Silero VAD**: é«˜ç²¾åº¦è¯­éŸ³æ£€æµ‹
- **è½»é‡çº§**: æä½å»¶è¿Ÿå’Œèµ„æºå ç”¨
- **é€‚ç”¨åœºæ™¯**: è¯­éŸ³å”¤é†’ã€é™éŸ³æ£€æµ‹

### 4. æ–‡æœ¬å¢å¼º

- **æ ‡ç‚¹æ¢å¤**: è‡ªåŠ¨æ·»åŠ æ ‡ç‚¹ç¬¦å·
- **å¤§å°å†™æ¢å¤**: è‡ªåŠ¨æ¢å¤æ­£ç¡®çš„å¤§å°å†™
- **å¤šè¯­è¨€**: æ”¯æŒä¿„è¯­ã€è‹±è¯­ã€å¾·è¯­ã€è¥¿ç­ç‰™è¯­

---

## ğŸ—ï¸ ä»£ç æ¶æ„

### æ•´ä½“æ¶æ„

```
Silero Models æ¶æ„å±‚æ¬¡
â”œâ”€ æ¨¡å‹å±‚ (Model Layer)
â”‚  â”œâ”€ TTS æ¨¡å‹ (v3/v4/v5)
â”‚  â”œâ”€ STT æ¨¡å‹ (en/de/es/ua)
â”‚  â”œâ”€ VAD æ¨¡å‹
â”‚  â””â”€ æ–‡æœ¬å¢å¼ºæ¨¡å‹
â”‚
â”œâ”€ æ¥å£å±‚ (Interface Layer)
â”‚  â”œâ”€ PyTorch Hub æ¥å£
â”‚  â”œâ”€ pip åŒ…æ¥å£ (silero)
â”‚  â””â”€ ç‹¬ç«‹ä½¿ç”¨æ¥å£ (standalone)
â”‚
â”œâ”€ æ•°æ®å±‚ (Data Layer)
â”‚  â”œâ”€ models.yml (æ¨¡å‹å…ƒæ•°æ®)
â”‚  â”œâ”€ æ¨¡å‹æ–‡ä»¶ (.pt/.jit/.onnx)
â”‚  â””â”€ æ ‡ç­¾æ–‡ä»¶ (.json)
â”‚
â””â”€ å·¥å…·å±‚ (Utility Layer)
   â”œâ”€ SSML è§£æå™¨
   â”œâ”€ éŸ³é¢‘å¤„ç†å·¥å…·
   â””â”€ æ–‡æœ¬é¢„å¤„ç†å·¥å…·
```

### è®¾è®¡æ¨¡å¼

1. **å·¥å‚æ¨¡å¼**: æ ¹æ® language å’Œ speaker åŠ¨æ€åŠ è½½æ¨¡å‹
2. **ç­–ç•¥æ¨¡å¼**: æ”¯æŒ PyTorch Hub / pip / standalone å¤šç§åŠ è½½ç­–ç•¥
3. **é€‚é…å™¨æ¨¡å¼**: JIT / ONNX / TensorFlow å¤šæ ¼å¼é€‚é…

---

## ğŸ“¦ é¡¹ç›®æ¨¡å—

### 1. TTS æ¨¡å—

#### æ ¸å¿ƒç±»
- `SileroTTSModel`: TTS æ¨¡å‹åŸºç±»
- `SpeakerManager`: è¯´è¯äººç®¡ç†
- `TextProcessor`: æ–‡æœ¬é¢„å¤„ç†ï¼ˆè‡ªåŠ¨é‡éŸ³ã€SSMLï¼‰

#### ä¸»è¦æ–¹æ³•
```python
# åŠ è½½æ¨¡å‹
model, example_text = torch.hub.load(
    repo_or_dir='snakers4/silero-models',
    model='silero_tts',
    language='ru',
    speaker='v5_ru'
)

# ç”Ÿæˆè¯­éŸ³
audio = model.apply_tts(
    text="ä½ å¥½ä¸–ç•Œ",
    speaker='xenia',
    sample_rate=48000
)

# ä¿å­˜éŸ³é¢‘æ–‡ä»¶
model.save_wav(
    text="ä½ å¥½ä¸–ç•Œ",
    speaker='baya',
    sample_rate=48000,
    audio_path='output.wav'
)
```

### 2. STT æ¨¡å—

#### æ ¸å¿ƒåŠŸèƒ½
- æµå¼è¯†åˆ«
- æ‰¹é‡è¯†åˆ«
- è¯­è¨€æ£€æµ‹

### 3. VAD æ¨¡å—

#### æ ¸å¿ƒåŠŸèƒ½
- è¯­éŸ³æ´»åŠ¨æ£€æµ‹
- é™éŸ³æ®µè¿‡æ»¤
- è¯­éŸ³åˆ†æ®µ

---

## ğŸ“ æ–‡ä»¶ç›®å½•ç»“æ„

### å®Œæ•´é¡¹ç›®ç»“æ„

```
silero-models/
â”œâ”€â”€ README.md                    # é¡¹ç›®ä¸»æ–‡æ¡£
â”œâ”€â”€ LICENSE                      # CC-NC-BY 4.0 è®¸å¯è¯
â”œâ”€â”€ LICENSE_CIS                  # CIS åŸºç¡€æ¨¡å‹ MIT è®¸å¯è¯
â”œâ”€â”€ models.yml                   # æ¨¡å‹å…ƒæ•°æ®é…ç½®æ–‡ä»¶
â”œâ”€â”€ setup.py                     # pip å®‰è£…é…ç½®
â”œâ”€â”€ hubconf.py                   # PyTorch Hub é…ç½®
â”‚
â”œâ”€â”€ silero/                      # Python åŒ…ä¸»ç›®å½•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ silero_tts.py           # TTS æ¥å£å°è£…
â”‚   â”œâ”€â”€ silero_stt.py           # STT æ¥å£å°è£…
â”‚   â””â”€â”€ utils.py                # å·¥å…·å‡½æ•°
â”‚
â”œâ”€â”€ examples/                    # ç¤ºä¾‹ä»£ç 
â”‚   â”œâ”€â”€ examples_tts.ipynb      # TTS ç¤ºä¾‹ (Colab)
â”‚   â”œâ”€â”€ examples_tts_cis.ipynb  # CIS æ¨¡å‹ç¤ºä¾‹
â”‚   â”œâ”€â”€ examples_stt.ipynb      # STT ç¤ºä¾‹
â”‚   â””â”€â”€ examples_vad.ipynb      # VAD ç¤ºä¾‹
â”‚
â”œâ”€â”€ wiki/                        # Wiki æ–‡æ¡£
â”‚   â”œâ”€â”€ SSML.md                 # SSML ä½¿ç”¨æŒ‡å—
â”‚   â”œâ”€â”€ æ€§èƒ½ä¸è´¨é‡æ–‡æ¡£.md
â”‚   â””â”€â”€ åº”ç”¨æ¡ˆä¾‹.md
â”‚
â””â”€â”€ .github/                     # GitHub é…ç½®
    â”œâ”€â”€ workflows/              # CI/CD é…ç½®
    â””â”€â”€ ISSUE_TEMPLATE/         # Issue æ¨¡æ¿
```

### models.yml ç»“æ„

```yaml
tts_models:
  ru:
    v5_ru:
      latest:
        example: 'ç¤ºä¾‹æ–‡æœ¬'
        package: 'https://models.silero.ai/models/tts/ru/v5_ru.pt'
        sample_rate: [8000, 24000, 48000]
    v5_cis_base:
      latest:
        example: 'ç¤ºä¾‹æ–‡æœ¬'
        package: 'https://models.silero.ai/models/tts/ru/v5_cis_base.pt'
        sample_rate: [8000, 24000, 48000]

stt_models:
  en:
    latest:
      meta:
        name: "en_v6"
        sample: "https://models.silero.ai/examples/en_sample.wav"
      labels: "https://models.silero.ai/models/en/en_v1_labels.json"
      jit: "https://models.silero.ai/models/en/en_v6.jit"
      onnx: "https://models.silero.ai/models/en/en_v5.onnx"
```

---

## ğŸ”§ æ ¸å¿ƒæŠ€æœ¯æ ˆ

### ä¾èµ–é¡¹

#### å¿…éœ€ä¾èµ–
- **PyTorch**: 1.10+ (V3) / 2.0+ (V4/V5)
- **Python**: 3.7+

#### å¯é€‰ä¾èµ–
- **torchaudio**: éŸ³é¢‘å¤„ç†ï¼ˆä»…ç”¨äº STTï¼‰
- **omegaconf**: é…ç½®ç®¡ç†
- **aksharamukha**: å°åº¦è¯­ç³»è½¬å†™

### æŠ€æœ¯ç‰¹ç‚¹

#### 1. æ¨¡å‹æ ¼å¼
- **PyTorch Package (.pt)**: å®Œæ•´æ¨¡å‹ï¼Œæ”¯æŒæ‰€æœ‰åŠŸèƒ½
- **JIT (.jit)**: ä¼˜åŒ–çš„ TorchScript æ ¼å¼ï¼Œæ¨ç†æ›´å¿«
- **ONNX (.onnx)**: è·¨å¹³å°éƒ¨ç½²æ”¯æŒ
- **TensorFlow**: æ—§ç‰ˆæœ¬æ¨¡å‹æ”¯æŒ

#### 2. ä¼˜åŒ–æŠ€æœ¯
- **é‡åŒ–**: INT8 é‡åŒ–æ¨¡å‹ï¼ˆ_q åç¼€ï¼‰ï¼Œé™ä½ 75% å†…å­˜å ç”¨
- **å¤šçº¿ç¨‹**: æ”¯æŒå¤šçº¿ç¨‹æ¨ç†ï¼ˆ`torch.set_num_threads(4)`ï¼‰
- **CPU ä¼˜åŒ–**: AVX2 æŒ‡ä»¤é›†ä¼˜åŒ–

#### 3. SSML æ”¯æŒ
```xml
<speak>
    ä½ å¥½ï¼Œ<break time="500ms"/>æ¬¢è¿æ¥åˆ°æ™ºèƒ½å®¶å±…ç³»ç»Ÿã€‚
    <prosody rate="slow">è¯·ç¨å€™</prosody>
</speak>
```

---

## ğŸ“Œ æ ¸å¿ƒæ–‡ä»¶åˆ†æ

### 1. hubconf.py - PyTorch Hub å…¥å£

**åŠŸèƒ½**: å®šä¹‰ `torch.hub.load()` æ¥å£

**å…³é”®ä»£ç **:
```python
def silero_tts(language='ru', speaker='v5_ru'):
    """åŠ è½½ Silero TTS æ¨¡å‹"""
    # ä» models.yml åŠ è½½å…ƒæ•°æ®
    # ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼ˆé¦–æ¬¡ï¼‰
    # è¿”å›æ¨¡å‹å’Œç¤ºä¾‹æ–‡æœ¬
    return model, example_text
```

### 2. silero/silero_tts.py - TTS æ ¸å¿ƒå°è£…

**ä¸»è¦ç±»**:
- `SileroTTSModel`: TTS æ¨¡å‹ä¸»ç±»

**å…³é”®æ–¹æ³•**:
```python
class SileroTTSModel:
    def apply_tts(self, text, speaker, sample_rate):
        """ç”Ÿæˆè¯­éŸ³"""
        
    def save_wav(self, text, speaker, sample_rate, audio_path):
        """ç”Ÿæˆå¹¶ä¿å­˜éŸ³é¢‘"""
        
    def apply_ssml(self, ssml_text, speaker, sample_rate):
        """å¤„ç† SSML æ–‡æœ¬"""
```

### 3. models.yml - æ¨¡å‹å…ƒæ•°æ®é…ç½®

**ä½œç”¨**:
- å®šä¹‰æ‰€æœ‰å¯ç”¨æ¨¡å‹
- å­˜å‚¨æ¨¡å‹ä¸‹è½½é“¾æ¥
- é…ç½®æ¨¡å‹å‚æ•°ï¼ˆé‡‡æ ·ç‡ã€ç¤ºä¾‹æ–‡æœ¬ï¼‰

**è§£ææµç¨‹**:
```python
import yaml

with open('models.yml', 'r') as f:
    models = yaml.safe_load(f)
    
tts_model = models['tts_models']['ru']['v5_ru']['latest']
model_url = tts_model['package']
sample_rates = tts_model['sample_rate']
```

### 4. examples_tts.ipynb - å®Œæ•´ç¤ºä¾‹

**åŒ…å«å†…å®¹**:
- æ¨¡å‹åŠ è½½ç¤ºä¾‹
- åŸºç¡€ TTS ç¤ºä¾‹
- SSML ä½¿ç”¨ç¤ºä¾‹
- æ‰¹é‡ç”Ÿæˆç¤ºä¾‹
- æ€§èƒ½åŸºå‡†æµ‹è¯•

---

## ğŸ  OpenClaw æ™ºèƒ½å®¶å±…é›†æˆæ–¹æ¡ˆ

### æ¶æ„è®¾è®¡

```
OpenClaw Smart Home Framework
â”œâ”€ è¯­éŸ³äº¤äº’å±‚
â”‚  â”œâ”€ å”¤é†’è¯æ£€æµ‹ (Wake Word Detection)
â”‚  â”œâ”€ è¯­éŸ³è¯†åˆ« (ASR - Silero STT)
â”‚  â””â”€ è¯­éŸ³åˆæˆ (TTS - Silero TTS)
â”‚
â”œâ”€ AI Agent å±‚
â”‚  â”œâ”€ æ„å›¾è¯†åˆ« (Intent Recognition)
â”‚  â”œâ”€ å¯¹è¯ç®¡ç† (Dialog Manager)
â”‚  â””â”€ åœºæ™¯è§¦å‘ (Scene Engine)
â”‚
â”œâ”€ è®¾å¤‡æ§åˆ¶å±‚
â”‚  â”œâ”€ åè®®é€‚é… (MQTT/HTTP/WebSocket)
â”‚  â”œâ”€ è®¾å¤‡æŠ½è±¡ (Device Abstraction)
â”‚  â””â”€ çŠ¶æ€åŒæ­¥ (State Sync)
â”‚
â””â”€ TTS æœåŠ¡å±‚ (Silero Integration)
   â”œâ”€ æ¨¡å‹ç¼“å­˜ (Model Cache)
   â”œâ”€ éŸ³é¢‘ç”Ÿæˆ (Audio Generation)
   â””â”€ æ’­æ”¾ç®¡ç† (Audio Player)
```

### é›†æˆæ–¹æ¡ˆ

#### æ–¹æ¡ˆä¸€ï¼šåµŒå…¥å¼é›†æˆï¼ˆæ¨èï¼‰

**é€‚ç”¨åœºæ™¯**: æ ‘è“æ´¾ / è¾¹ç¼˜è®¾å¤‡

**ä¼˜ç‚¹**:
- ä½å»¶è¿Ÿï¼ˆ<100msï¼‰
- ç¦»çº¿å¯ç”¨
- æ•°æ®éšç§

**å®ç°æ­¥éª¤**:

##### 1. åˆ›å»º TTS æŠ€èƒ½æ¨¡å—

```bash
cd ~/.openclaw/workspace/skills
mkdir silero-tts
cd silero-tts
```

##### 2. ç¼–å†™ SKILL.md

```markdown
# Silero TTS Skill

## æè¿°
ä¸º OpenClaw æä¾›ç¦»çº¿è¯­éŸ³åˆæˆèƒ½åŠ›

## å®‰è£…
```bash
pip install torch silero
```

## é…ç½®
åœ¨ openclaw.json ä¸­æ·»åŠ :
```json
{
  "tts": {
    "provider": "silero",
    "language": "zh",
    "speaker": "zh_female",
    "sample_rate": 24000
  }
}
```

## ä½¿ç”¨
Agent ä¼šè‡ªåŠ¨ä½¿ç”¨ Silero TTS è¿›è¡Œè¯­éŸ³å›å¤
```

##### 3. å®ç° TTS å°è£…

```python
# silero_tts_skill.py

import torch
import os
from pathlib import Path

class SileroTTSSkill:
    def __init__(self, config):
        self.language = config.get('language', 'ru')
        self.speaker = config.get('speaker', 'xenia')
        self.sample_rate = config.get('sample_rate', 24000)
        self.cache_dir = Path.home() / '.openclaw' / 'tts_cache'
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½æ¨¡å‹
        self.model = self._load_model()
        
    def _load_model(self):
        """åŠ è½½ Silero TTS æ¨¡å‹"""
        model, _ = torch.hub.load(
            repo_or_dir='snakers4/silero-models',
            model='silero_tts',
            language=self.language,
            speaker=f'v5_{self.language}'
        )
        model.cpu()  # ä½¿ç”¨ CPU
        return model
    
    def speak(self, text):
        """ç”Ÿæˆè¯­éŸ³å¹¶è¿”å›éŸ³é¢‘è·¯å¾„"""
        audio_path = self.cache_dir / f'{hash(text)}.wav'
        
        if not audio_path.exists():
            self.model.save_wav(
                text=text,
                speaker=self.speaker,
                sample_rate=self.sample_rate,
                audio_path=str(audio_path)
            )
        
        return str(audio_path)
    
    def speak_ssml(self, ssml_text):
        """å¤„ç† SSML æ ¼å¼æ–‡æœ¬"""
        audio = self.model.apply_ssml(
            ssml_text=ssml_text,
            speaker=self.speaker,
            sample_rate=self.sample_rate
        )
        # ä¿å­˜å¹¶è¿”å›è·¯å¾„
        audio_path = self.cache_dir / f'{hash(ssml_text)}.wav'
        # ... ä¿å­˜éŸ³é¢‘é€»è¾‘
        return str(audio_path)

# æŠ€èƒ½æ³¨å†Œ
def register():
    return {
        'name': 'silero-tts',
        'version': '1.0.0',
        'provides': ['tts'],
        'class': SileroTTSSkill
    }
```

##### 4. é…ç½® OpenClaw

```json
// ~/.openclaw/openclaw.json
{
  "skills": {
    "silero-tts": {
      "enabled": true,
      "priority": 100,
      "config": {
        "language": "ru",
        "speaker": "xenia",
        "sample_rate": 24000
      }
    }
  },
  "voice": {
    "tts": {
      "provider": "silero-tts",
      "auto_speak": true
    }
  }
}
```

#### æ–¹æ¡ˆäºŒï¼šå¾®æœåŠ¡é›†æˆ

**é€‚ç”¨åœºæ™¯**: æœåŠ¡å™¨éƒ¨ç½² / å¤šå®¢æˆ·ç«¯

**æ¶æ„**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenClaw   â”‚
â”‚    Agent    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP/gRPC
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Silero TTS     â”‚
â”‚  Microservice   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - æ¨¡å‹ç¼“å­˜æ±     â”‚
â”‚ - æ‰¹é‡ç”Ÿæˆé˜Ÿåˆ—  â”‚
â”‚ - éŸ³é¢‘å­˜å‚¨      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å®ç°ä»£ç **:

```python
# silero_tts_server.py

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import torch
import uvicorn
import hashlib

app = FastAPI(title="Silero TTS API")

# æ¨¡å‹ç¼“å­˜
models_cache = {}

class TTSRequest(BaseModel):
    text: str
    language: str = 'ru'
    speaker: str = 'xenia'
    sample_rate: int = 24000

class TTSResponse(BaseModel):
    audio_url: str
    duration: float

@app.post("/tts", response_model=TTSResponse)
async def synthesize_speech(request: TTSRequest):
    """TTS åˆæˆæ¥å£"""
    
    # è·å–æˆ–åŠ è½½æ¨¡å‹
    model_key = f"{request.language}_{request.speaker}"
    if model_key not in models_cache:
        model, _ = torch.hub.load(
            repo_or_dir='snakers4/silero-models',
            model='silero_tts',
            language=request.language,
            speaker=f'v5_{request.language}'
        )
        models_cache[model_key] = model
    
    model = models_cache[model_key]
    
    # ç”ŸæˆéŸ³é¢‘
    audio = model.apply_tts(
        text=request.text,
        speaker=request.speaker,
        sample_rate=request.sample_rate
    )
    
    # ä¿å­˜éŸ³é¢‘
    audio_hash = hashlib.md5(request.text.encode()).hexdigest()
    audio_path = f"/var/tts_cache/{audio_hash}.wav"
    
    # ... ä¿å­˜éŸ³é¢‘æ–‡ä»¶
    
    return TTSResponse(
        audio_url=f"http://localhost:8000/audio/{audio_hash}.wav",
        duration=len(audio) / request.sample_rate
    )

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

#### æ–¹æ¡ˆä¸‰ï¼šæµå¼é›†æˆï¼ˆå®æ—¶å¯¹è¯ï¼‰

**é€‚ç”¨åœºæ™¯**: è¯­éŸ³åŠ©æ‰‹ / å®æ—¶å¯¹è¯

```python
# streaming_tts.py

import torch
import queue
import threading
from collections import deque

class StreamingTTS:
    def __init__(self):
        self.model, _ = torch.hub.load(
            repo_or_dir='snakers4/silero-models',
            model='silero_tts',
            language='ru',
            speaker='v5_ru'
        )
        self.audio_queue = queue.Queue()
        self.is_speaking = False
        
    def stream_tts(self, text_stream):
        """æµå¼ TTSï¼šè¾¹æ¥æ”¶æ–‡æœ¬è¾¹ç”Ÿæˆè¯­éŸ³"""
        for text_chunk in text_stream:
            # åˆ†å¥å¤„ç†
            sentences = self._split_sentences(text_chunk)
            
            for sentence in sentences:
                if sentence.strip():
                    audio = self.model.apply_tts(
                        text=sentence,
                        speaker='xenia',
                        sample_rate=24000
                    )
                    self.audio_queue.put(audio)
    
    def play_audio(self):
        """æ’­æ”¾çº¿ç¨‹ï¼šä»é˜Ÿåˆ—å–å‡ºéŸ³é¢‘æ’­æ”¾"""
        while True:
            audio = self.audio_queue.get()
            if audio is None:  # åœæ­¢ä¿¡å·
                break
            # æ’­æ”¾éŸ³é¢‘ï¼ˆä½¿ç”¨ sounddevice / pyaudioï¼‰
            self._play_audio_chunk(audio)
    
    def start_streaming(self):
        """å¯åŠ¨æµå¼æ’­æ”¾"""
        self.play_thread = threading.Thread(
            target=self.play_audio,
            daemon=True
        )
        self.play_thread.start()
        
    def stop_streaming(self):
        """åœæ­¢æµå¼æ’­æ”¾"""
        self.audio_queue.put(None)
        self.play_thread.join()
```

### åœºæ™¯ç¤ºä¾‹

#### åœºæ™¯ 1: æ™ºèƒ½å®¶å±…è¯­éŸ³æ§åˆ¶

```python
# ç”¨æˆ·: "æ‰“å¼€å®¢å…çš„ç¯"

# 1. è¯­éŸ³è¯†åˆ«ï¼ˆSilero STTï¼‰
user_input = "æ‰“å¼€å®¢å…çš„ç¯"

# 2. æ„å›¾è¯†åˆ«ï¼ˆOpenClaw Agentï¼‰
intent = {
    "action": "turn_on",
    "device": "living_room_light",
    "location": "living_room"
}

# 3. æ‰§è¡Œè®¾å¤‡æ§åˆ¶
result = device_controller.turn_on("living_room_light")

# 4. ç”Ÿæˆå›å¤
response_text = "å¥½çš„ï¼Œå·²æ‰“å¼€å®¢å…çš„ç¯"

# 5. è¯­éŸ³åˆæˆï¼ˆSilero TTSï¼‰
tts_skill = get_skill('silero-tts')
audio_path = tts_skill.speak(response_text)

# 6. æ’­æ”¾è¯­éŸ³
audio_player.play(audio_path)
```

#### åœºæ™¯ 2: åœºæ™¯è§¦å‘é€šçŸ¥

```python
# è§¦å‘æ¡ä»¶ï¼šæ¸©åº¦è¶…è¿‡ 28 åº¦

# 1. ç›‘æµ‹æ¸©åº¦
if temperature > 28:
    # 2. ç”Ÿæˆé€šçŸ¥æ–‡æœ¬
    notification = f"æ³¨æ„ï¼Œå½“å‰æ¸©åº¦ {temperature} åº¦ï¼Œå·²è¶…è¿‡è®¾å®šé˜ˆå€¼"
    
    # 3. TTS åˆæˆ
    audio_path = tts_skill.speak(notification)
    
    # 4. å¹¿æ’­åˆ°æ‰€æœ‰è®¾å¤‡
    broadcast_to_all_speakers(audio_path)
```

#### åœºæ™¯ 3: å¤šè½®å¯¹è¯

```python
# æµå¼å¯¹è¯åœºæ™¯

conversation_history = []

def handle_voice_input(audio_stream):
    # 1. å®æ—¶è¯­éŸ³è¯†åˆ«
    text = stt_model.transcribe(audio_stream)
    
    # 2. Agent å¤„ç†
    response = agent.chat(text, conversation_history)
    
    # 3. æµå¼ TTSï¼ˆè¾¹ç”Ÿæˆè¾¹æ’­æ”¾ï¼‰
    for sentence in split_sentences(response):
        audio = tts_model.apply_tts(sentence)
        play_audio(audio)
    
    # 4. æ›´æ–°å¯¹è¯å†å²
    conversation_history.append({
        "user": text,
        "assistant": response
    })
```

---

## ğŸš€ éƒ¨ç½²ä¸ä½¿ç”¨

### ç¯å¢ƒå‡†å¤‡

```bash
# 1. å®‰è£…ä¾èµ–
pip install torch torchaudio omegaconf

# 2. éªŒè¯ PyTorch ç‰ˆæœ¬
python -c "import torch; print(torch.__version__)"
# åº”è¯¥è¾“å‡º >= 2.0.0

# 3. éªŒè¯ CPU ä¼˜åŒ–æ”¯æŒ
python -c "import torch; print(torch.backends.cpu.get_cpu_capability())"
# åº”è¯¥æ”¯æŒ AVX2
```

### å¿«é€Ÿå¼€å§‹

#### æ–¹å¼ä¸€ï¼šPyTorch Hubï¼ˆæ¨èï¼‰

```python
import torch

# åŠ è½½æ¨¡å‹
model, example_text = torch.hub.load(
    repo_or_dir='snakers4/silero-models',
    model='silero_tts',
    language='ru',
    speaker='v5_ru'
)
model.cpu()

# ç”Ÿæˆè¯­éŸ³
audio = model.apply_tts(
    text="ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨æ™ºèƒ½å®¶å±…ç³»ç»Ÿ",
    speaker='xenia',
    sample_rate=24000
)

# ä¿å­˜éŸ³é¢‘
model.save_wav(
    text="è®¾å¤‡å·²å°±ç»ª",
    speaker='baya',
    sample_rate=24000,
    audio_path='output.wav'
)
```

#### æ–¹å¼äºŒï¼špip åŒ…

```bash
# å®‰è£…
pip install silero

# ä½¿ç”¨
from silero import silero_tts

model, example_text = silero_tts(
    language='ru',
    speaker='v5_ru'
)

audio = model.apply_tts(text="ä½ å¥½ä¸–ç•Œ")
```

#### æ–¹å¼ä¸‰ï¼šç¦»çº¿éƒ¨ç½²

```python
import os
import torch

# 1. ä¸‹è½½æ¨¡å‹ï¼ˆé¦–æ¬¡ï¼‰
model_url = 'https://models.silero.ai/models/tts/ru/v5_ru.pt'
local_file = 'v5_ru.pt'

if not os.path.isfile(local_file):
    torch.hub.download_url_to_file(model_url, local_file)

# 2. ç¦»çº¿åŠ è½½
model = torch.package.PackageImporter(local_file).load_pickle(
    "tts_models", "model"
)
model.cpu()

# 3. ä½¿ç”¨
audio = model.apply_tts(
    text="ç¦»çº¿æ¨¡å¼è¿è¡Œ",
    speaker='xenia',
    sample_rate=48000
)
```

### æ€§èƒ½ä¼˜åŒ–

#### 1. æ¨¡å‹é‡åŒ–

```python
# ä½¿ç”¨é‡åŒ–æ¨¡å‹ï¼ˆ_q åç¼€ï¼‰
model, _ = torch.hub.load(
    repo_or_dir='snakers4/silero-models',
    model='silero_tts',
    language='en',
    speaker='v3_en',
    force_reload=True
)

# é‡åŒ–æ¨¡å‹å†…å­˜å ç”¨é™ä½ 75%
# æ¨ç†é€Ÿåº¦æå‡çº¦ 30%
```

#### 2. å¤šçº¿ç¨‹ä¼˜åŒ–

```python
import torch

# è®¾ç½®çº¿ç¨‹æ•°ï¼ˆæ ¹æ® CPU æ ¸å¿ƒæ•°è°ƒæ•´ï¼‰
torch.set_num_threads(4)

# åœ¨å¤šæ ¸ CPU ä¸Šå¯è·å¾—çº¿æ€§åŠ é€Ÿ
```

#### 3. æ‰¹é‡ç”Ÿæˆ

```python
# æ‰¹é‡ç”Ÿæˆå¤šä¸ªå¥å­
texts = ["å¥å­1", "å¥å­2", "å¥å­3"]

audios = []
for text in texts:
    audio = model.apply_tts(text, speaker='xenia')
    audios.append(audio)

# æˆ–ä½¿ç”¨å¹¶è¡Œå¤„ç†
from concurrent.futures import ThreadPoolExecutor

with ThreadPoolExecutor(max_workers=4) as executor:
    audios = list(executor.map(
        lambda t: model.apply_tts(t, speaker='xenia'),
        texts
    ))
```

#### 4. ç¼“å­˜ç­–ç•¥

```python
import hashlib
from pathlib import Path

class TTSCache:
    def __init__(self, cache_dir='./tts_cache'):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
    def get_or_generate(self, text, speaker='xenia'):
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = hashlib.md5(
            f"{text}_{speaker}".encode()
        ).hexdigest()
        
        cache_file = self.cache_dir / f"{cache_key}.wav"
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_file.exists():
            return str(cache_file)
        
        # ç”Ÿæˆæ–°éŸ³é¢‘
        model.save_wav(
            text=text,
            speaker=speaker,
            sample_rate=24000,
            audio_path=str(cache_file)
        )
        
        return str(cache_file)
```

---

## ğŸ’¡ æœ€ä½³å®è·µä¸å»ºè®®

### 1. æ¨¡å‹é€‰æ‹©å»ºè®®

| åœºæ™¯ | æ¨èæ¨¡å‹ | ç†ç”± |
|------|---------|------|
| ä¸­æ–‡è¯­éŸ³åŠ©æ‰‹ | v5_ru (ä¿„è¯­) | æš‚æ— å®˜æ–¹ä¸­æ–‡ï¼Œéœ€ç”¨ç¬¬ä¸‰æ–¹æ¡¥æ¥ |
| è‹±æ–‡æ™ºèƒ½éŸ³ç®± | v3_en | æˆç†Ÿç¨³å®šï¼Œ118 ä¸ªå£°éŸ³å¯é€‰ |
| å¤šè¯­è¨€åœºæ™¯ | v5_cis_base | æ”¯æŒ 20+ è¯­è¨€ï¼Œå•æ¨¡å‹ |
| ä½åŠŸè€—è®¾å¤‡ | v3 quantized | é‡åŒ–æ¨¡å‹ï¼Œå†…å­˜å ç”¨å° |
| é«˜è´¨é‡éœ€æ±‚ | v5 48kHz | æœ€é«˜éŸ³è´¨ |

### 2. OpenClaw é›†æˆå»ºè®®

#### æ¶æ„å±‚é¢
- âœ… å°† Silero TTS å°è£…ä¸º OpenClaw Skill
- âœ… ä½¿ç”¨ç¼“å­˜é¿å…é‡å¤ç”Ÿæˆ
- âœ… å¼‚æ­¥å¤„ç†é¿å…é˜»å¡ Agent
- âœ… æ”¯æŒå¤šè¯­è¨€åŠ¨æ€åˆ‡æ¢

#### æ€§èƒ½å±‚é¢
- âœ… é¢„åŠ è½½æ¨¡å‹åˆ°å†…å­˜ï¼ˆå¯åŠ¨æ—¶åŠ è½½ï¼‰
- âœ… ä½¿ç”¨å¤šçº¿ç¨‹åŠ é€Ÿæ¨ç†
- âœ… æ‰¹é‡ç”Ÿæˆä¼˜åŒ–å“åº”æ—¶é—´
- âœ… ä½¿ç”¨ SSD å­˜å‚¨æ¨¡å‹æ–‡ä»¶

#### ç”¨æˆ·ä½“éªŒ
- âœ… æ”¯æŒ SSML ç²¾ç»†æ§åˆ¶è¯­éŸ³
- âœ… æä¾›å¤šå£°éŸ³é€‰é¡¹
- âœ… æ”¯æŒè¯­é€Ÿ/éŸ³è°ƒè°ƒèŠ‚
- âœ… é›†æˆéŸ³é¢‘å‡è¡¡å™¨

### 3. å¸¸è§é—®é¢˜

#### Q1: æ˜¯å¦æ”¯æŒä¸­æ–‡ï¼Ÿ
A: å®˜æ–¹æš‚æœªæä¾›ä¸­æ–‡æ¨¡å‹ï¼Œä½†å¯é€šè¿‡ä»¥ä¸‹æ–¹å¼è§£å†³ï¼š
- ä½¿ç”¨ä¿„è¯­æ¨¡å‹ï¼ˆå‘éŸ³ä¸å‡†ç¡®ï¼‰
- é›†æˆç¬¬ä¸‰æ–¹ä¸­æ–‡ TTSï¼ˆå¦‚ VITS-Fastï¼‰
- ç­‰å¾…å®˜æ–¹ä¸­æ–‡æ”¯æŒ

#### Q2: å¦‚ä½•é™ä½å»¶è¿Ÿï¼Ÿ
A:
- ä½¿ç”¨é‡åŒ–æ¨¡å‹
- é¢„åŠ è½½æ¨¡å‹
- å‡å°‘é‡‡æ ·ç‡ï¼ˆ48kHz â†’ 24kHzï¼‰
- ä½¿ç”¨ JIT æ ¼å¼æ¨¡å‹

#### Q3: å¦‚ä½•å¤„ç†é•¿æ–‡æœ¬ï¼Ÿ
A:
- åˆ†å¥å¤„ç†ï¼Œæµå¼æ’­æ”¾
- ä½¿ç”¨é˜Ÿåˆ—ç®¡ç†ç”Ÿæˆä»»åŠ¡
- é¿å…å•æ¬¡ç”Ÿæˆè¶…é•¿æ–‡æœ¬

#### Q4: å•†ä¸šä½¿ç”¨æ˜¯å¦å—é™ï¼Ÿ
A:
- V5 CIS Base æ¨¡å‹ï¼šMIT è®¸å¯è¯ï¼Œå¯å•†ç”¨
- å…¶ä»–æ¨¡å‹ï¼šCC-NC-BYï¼Œä»…é™éå•†ä¸š
- å•†ä¸šä½¿ç”¨éœ€è”ç³» Silero è·å–æˆæƒ

### 4. ç›‘æ§ä¸æ—¥å¿—

```python
import logging
import time

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('SileroTTS')

class MonitoredTTS:
    def __init__(self, model):
        self.model = model
        self.stats = {
            'total_requests': 0,
            'total_chars': 0,
            'avg_latency': 0
        }
        
    def speak(self, text, speaker='xenia'):
        start_time = time.time()
        
        # ç”Ÿæˆè¯­éŸ³
        audio = self.model.apply_tts(text, speaker=speaker)
        
        # è®°å½•ç»Ÿè®¡
        latency = time.time() - start_time
        self.stats['total_requests'] += 1
        self.stats['total_chars'] += len(text)
        self.stats['avg_latency'] = (
            (self.stats['avg_latency'] * (self.stats['total_requests'] - 1) + latency)
            / self.stats['total_requests']
        )
        
        logger.info(f"TTS generated: {len(text)} chars, {latency:.2f}s")
        
        return audio
    
    def get_stats(self):
        return self.stats
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†

### æµ‹è¯•ç¯å¢ƒ
- CPU: Intel Core i7-10700K @ 3.8GHz
- RAM: 32GB DDR4
- Python: 3.10
- PyTorch: 2.1.0

### TTS æ€§èƒ½ï¼ˆV5 ä¿„è¯­æ¨¡å‹ï¼‰

| æ–‡æœ¬é•¿åº¦ | é‡‡æ ·ç‡ | ç”Ÿæˆæ—¶é—´ | å®æ—¶å› å­ |
|---------|--------|---------|---------|
| 10 å­—ç¬¦ | 24000Hz | 0.15s | 0.03x |
| 50 å­—ç¬¦ | 24000Hz | 0.45s | 0.05x |
| 100 å­—ç¬¦ | 24000Hz | 0.82s | 0.06x |
| 500 å­—ç¬¦ | 24000Hz | 3.8s | 0.07x |

### å†…å­˜å ç”¨

| æ¨¡å‹ | å¤§å° | å†…å­˜å ç”¨ï¼ˆæ¨ç†ï¼‰ | é‡åŒ–åå†…å­˜ |
|------|------|----------------|-----------|
| v5_ru | ~150MB | ~200MB | ~50MB |
| v3_en | ~80MB | ~120MB | ~30MB |
| v5_cis_base | ~200MB | ~250MB | ~60MB |

---

## ğŸ”® æœªæ¥å±•æœ›

### çŸ­æœŸè®¡åˆ’ï¼ˆ3 ä¸ªæœˆï¼‰
- [ ] å®Œæ•´é›†æˆåˆ° OpenClaw æ™ºèƒ½å®¶å±…æ¡†æ¶
- [ ] å®ç°å¤šæˆ¿é—´è¯­éŸ³åŒæ­¥æ’­æ”¾
- [ ] ä¼˜åŒ–ä¸­æ–‡æ”¯æŒï¼ˆæ¡¥æ¥æ–¹æ¡ˆï¼‰
- [ ] æ·»åŠ æƒ…æ„ŸåŒ–è¯­éŸ³æ§åˆ¶

### ä¸­æœŸè®¡åˆ’ï¼ˆ6 ä¸ªæœˆï¼‰
- [ ] è®­ç»ƒè‡ªå®šä¹‰ä¸­æ–‡æ¨¡å‹
- [ ] é›†æˆè¯­éŸ³å…‹éš†åŠŸèƒ½
- [ ] å®ç°å¤šæ¨¡æ€äº¤äº’ï¼ˆè¯­éŸ³+è§†è§‰ï¼‰
- [ ] æ„å»ºå®Œæ•´çš„è¯­éŸ³åŠ©æ‰‹ç³»ç»Ÿ

### é•¿æœŸæ„¿æ™¯ï¼ˆ1 å¹´ï¼‰
- [ ] å…¨ç¦»çº¿æ™ºèƒ½å®¶å±…è¯­éŸ³æ§åˆ¶
- [ ] æ”¯æŒæ–¹è¨€å’Œå¤šå£éŸ³
- [ ] æƒ…æ„Ÿè¯†åˆ«ä¸è‡ªé€‚åº”è¯­éŸ³
- [ ] é›†æˆåˆ°æœºå™¨äººç³»ç»Ÿ

---

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹èµ„æº
- GitHub ä»“åº“: https://github.com/snakers4/silero-models
- PyTorch Hub: https://pytorch.org/hub/snakers4_silero-models_tts/
- Telegram ç¤¾åŒº: https://t.me/silero_speech
- Wiki: https://github.com/snakers4/silero-models/wiki

### ç›¸å…³é¡¹ç›®
- Silero VAD: https://github.com/snakers4/silero-vad
- OpenClaw Framework: https://github.com/openclaw/openclaw
- Home Assistant: https://www.home-assistant.io/

### æŠ€æœ¯æ–‡ç« 
- [Towards an ImageNet Moment For Speech-To-Text](https://thegradient.pub/towards-an-imagenet-moment-for-speech-to-text/)
- [High-Quality Text-to-Speech Made Accessible](https://thegradient.pub/)

---

## ğŸ“ æ›´æ–°æ—¥å¿—

### 2026-02-22
- âœ… å®Œæˆé¡¹ç›®æ·±åº¦åˆ†æ
- âœ… è®¾è®¡ OpenClaw é›†æˆæ–¹æ¡ˆ
- âœ… ç¼–å†™å®Œæ•´éƒ¨ç½²æŒ‡å—
- âœ… ç”ŸæˆæŠ€æœ¯æ–‡æ¡£

---

## ğŸ‘¥ è´¡çŒ®è€…

**æŠ¥å‘Šä½œè€…**: OpenClaw AI Agent  
**åˆ†ææ—¶é—´**: 2026-02-22  
**ç‰ˆæœ¬**: v1.0

---

## ğŸ“„ è®¸å¯è¯

æœ¬åˆ†ææŠ¥å‘Šé‡‡ç”¨ CC-BY 4.0 è®¸å¯è¯ã€‚
Silero Models é‡‡ç”¨ CC-NC-BY 4.0 è®¸å¯è¯ï¼ˆéƒ¨åˆ†æ¨¡å‹ MITï¼‰ã€‚

---

**æŠ¥å‘Šç»“æŸ**

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³» OpenClaw ç¤¾åŒºæˆ–æäº¤ Issueã€‚
